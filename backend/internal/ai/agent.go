package ai

import (
	"bufio"
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"rag-searchbot-backend/internal/models"
	"rag-searchbot-backend/internal/post"
	"strings"

	"github.com/gin-gonic/gin"
)

// Intent represents the type of user question.
type Intent string

const (
	IntentBlogQuestion     Intent = "blog_question"
	IntentSummarizePost    Intent = "summarize_post"
	IntentSearchBlog       Intent = "search_blog"
	IntentGeneric          Intent = "generic_question"
	IntentUnknown          Intent = "unknown"
	IntentGreetingFarewell Intent = "greeting_farewell"
)

// Agent is the interface for all agents.
type Agent interface {
	Handle(question string, ctx *AgentContext) (string, error)
}

// AgentContext provides context for agent processing.
type AgentContext struct {
	Post    *models.Post
	User    *models.User
	PosRepo post.PostRepositoryInterface
	// ‡πÄ‡∏û‡∏¥‡πà‡∏° field ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô Embeddings, Logger, etc.
}

// ErrInsufficientContext is returned by BlogAgent when RAG context is not enough.
var ErrInsufficientContext = fmt.Errorf("insufficient context for RAG")

// IntentClassifier uses LLM (OpenRouter) to classify the question intent.
func IntentClassifier(question string) Intent {
	// Prepare system prompt for LLM
	systemPrompt := `
You are an intent classifier for a blog Q&A system. 
Classify the user's question into one of these intents:
- blog_question: ‡∏ñ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£", "RAG ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£"
- summarize_post: ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢"
- search_blog: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡∏°‡∏µ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á Next.js ‡πÑ‡∏´‡∏°"
- generic_question: ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ä‡πà‡∏ô "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏≠‡∏¢"
- greeting_farewell: ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏•‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô"
- unknown: ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°`

	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": false,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}
	config := map[string]string{
		"api_key":       os.Getenv("AI_API_KEY"),
		"model":         os.Getenv("AI_MODEL"),
		"host":          os.Getenv("AI_HOST"),
		"use_self_host": os.Getenv("AI_SELF_HOST"),
	}
	log.Printf("IntentClassifier payload: %+v", payload)
	resp, err := SendLLMRequestToOpenRouter(payload, config)
	if err != nil {
		log.Printf("IntentClassifier error: %v", err)
		return IntentUnknown
	}

	// log.Printf("IntentClassifier LLM raw response: %q", resp)
	return parseIntentFromLLM(resp)
}

// Helper methods
func writeEvent(c *gin.Context, event, data string) {
	fmt.Fprintf(c.Writer, "event: %s\ndata: %s\n\n", event, data)
	c.Writer.Flush()
}

func writeErrorEvent(c *gin.Context, message string) {
	fmt.Fprintf(c.Writer, "event: error\ndata: %s\n\n", message)
	c.Writer.Flush()
}

func parseStreamChunk(raw []byte) string {
	var chunk map[string]interface{}
	if err := json.Unmarshal(raw, &chunk); err != nil {
		return ""
	}

	// Handle Ollama format
	if message, ok := chunk["message"].(map[string]interface{}); ok {
		if content, ok := message["content"].(string); ok {
			return content
		}
	}

	// Handle OpenAI/OpenRouter format
	if choices, ok := chunk["choices"].([]interface{}); ok && len(choices) > 0 {
		choice := choices[0].(map[string]interface{})
		if delta, ok := choice["delta"].(map[string]interface{}); ok {
			if content, ok := delta["content"].(string); ok {
				return content
			}
		}
	}

	return ""
}

// CASE : Summarize post agent
func StreamPostSummaryAgent(c *gin.Context, question string, htmlContent string) {
	// 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á system prompt
	systemPrompt := fmt.Sprintf(`‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô BSO Space Blog
‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£
-----
%s
-----`, htmlContent)

	// 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì token
	// inputText := systemPrompt + "\n" + question
	// inputTokens := token.CountTokens(inputText)

	// 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° payload
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": true,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}

	// 4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° HTTP request
	body, _ := json.Marshal(payload)
	req, _ := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+os.Getenv("AI_API_KEY"))
	req.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	req.Header.Set("X-Title", "https://blog.bsospace.com")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil || resp.StatusCode != http.StatusOK {
		writeErrorEvent(c, "‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ LLM ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
		return
	}
	defer resp.Body.Close()

	// 5. ‡∏ï‡∏±‡πâ‡∏á header ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SSE
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Writer.Flush()

	// 6. ‡∏™‡πà‡∏á event ‡πÄ‡∏£‡∏¥‡πà‡∏°
	writeEvent(c, "start", "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤")

	// 7. ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á stream
	streamLLMResponse(c, resp)

	// 8. ‡∏™‡πà‡∏á event ‡∏à‡∏ö
	writeEvent(c, "end", "‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
}

// CASE: greeting_farewell

func StreamGreetingFarewellAgent(c *gin.Context, question string) {
	// 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á system prompt
	systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏•‡∏≤‡πÉ‡∏ô BSO Space
‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏•‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏†‡∏≤‡∏û 
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ` + question

	// 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° payload
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": true,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}

	// 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° HTTP request
	body, _ := json.Marshal(payload)
	req, _ := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+os.Getenv("AI_API_KEY"))
	req.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	req.Header.Set("X-Title", "https://blog.bsospace.com")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil || resp.StatusCode != http.StatusOK {
		writeErrorEvent(c, "‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ LLM ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
		return
	}
	defer resp.Body.Close()

	// 4. ‡∏ï‡∏±‡πâ‡∏á header ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SSE
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Writer.Flush()

	// 5. ‡∏™‡πà‡∏á event ‡πÄ‡∏£‡∏¥‡πà‡∏°
	writeEvent(c, "start", "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢/‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏•‡∏≤")

	// 6. ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á stream
	streamLLMResponse(c, resp)

	// 7. ‡∏™‡πà‡∏á event ‡∏à‡∏ö
	writeEvent(c, "end", "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢/‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏•‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
}

// parseIntentFromLLM extracts the intent keyword from LLM response.
func parseIntentFromLLM(resp string) Intent {
	resp = strings.TrimSpace(resp)
	// Try to parse as JSON (OpenRouter format)
	var parsed struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
		} `json:"choices"`
	}
	if err := json.Unmarshal([]byte(resp), &parsed); err == nil && len(parsed.Choices) > 0 {
		intent := strings.TrimSpace(parsed.Choices[0].Message.Content)
		switch intent {
		case "blog_question":
			return IntentBlogQuestion
		case "summarize_post":
			return IntentSummarizePost
		case "search_blog":
			return IntentSearchBlog
		case "generic_question":
			return IntentGeneric
		case "greeting_farewell":
			return IntentGreetingFarewell
		default:
			return IntentUnknown
		}
	}

	// fallback: direct string match
	resp = strings.ToLower(resp)
	switch resp {
	case "blog_question":
		return IntentBlogQuestion
	case "summarize_post":
		return IntentSummarizePost
	case "search_blog":
		return IntentSearchBlog
	case "generic_question":
		return IntentGeneric
	case "greeting_farewell":
		return IntentGreetingFarewell
	default:
		return IntentUnknown
	}
}

// SendLLMRequestToOpenRouter is a utility for agents to call OpenRouter or Ollama.
// Returns the response body as a string (for non-streaming use).
func SendLLMRequestToOpenRouter(payload map[string]interface{}, config map[string]string) (string, error) {
	body, _ := json.Marshal(payload)

	useSelfHost := config["use_self_host"] == "true"
	if useSelfHost {
		host := config["host"]
		resp, err := http.Post(host+"/api/chat", "application/json", bytes.NewBuffer(body))
		if err != nil {
			return "", err
		}
		defer resp.Body.Close()
		respBody, _ := io.ReadAll(resp.Body)
		if resp.StatusCode != http.StatusOK {
			return "", fmt.Errorf("Ollama error: %s", string(respBody))
		}
		return string(respBody), nil
	}

	apiKey := config["api_key"]
	if apiKey == "" {
		return "", fmt.Errorf("OpenRouter API key missing")
	}
	request, err := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	if err != nil {
		return "", err
	}
	request.Header.Set("Content-Type", "application/json")
	request.Header.Set("Authorization", "Bearer "+apiKey)
	request.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	request.Header.Set("X-Title", "https://blog.bsospace.com")
	client := &http.Client{}
	log.Printf("Sending intent classification to OpenRouter: %+v", payload)
	resp, err := client.Do(request)
	log.Printf("OpenRouter response status: %v", resp.StatusCode)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()
	respBody, _ := io.ReadAll(resp.Body)
	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("OpenRouter error: %s", string(respBody))
	}
	return string(respBody), nil
}

// BlogAgent handles blog content questions and generic questions.
type BlogAgent struct{}

// streamLLMResponse streams LLM response and calls onChunk for each content chunk.
func streamLLMResponse(c *gin.Context, resp *http.Response) string {
	reader := bufio.NewReader(resp.Body)
	var fullText strings.Builder

	for {
		line, err := reader.ReadBytes('\n')
		if err != nil {
			if err == io.EOF {
				// a.logger.Info("LLM stream finished")
				writeEvent(c, "end", "done")
			} else {
				// a.logger.Error("Error reading LLM stream", zap.Error(err))
				writeErrorEvent(c, "Stream reading error")
			}
			break
		}

		if !bytes.HasPrefix(line, []byte("data: ")) {
			continue
		}

		raw := bytes.TrimSpace(line[6:])
		if len(raw) == 0 {
			continue
		}

		if bytes.Equal(raw, []byte("[DONE]")) {
			// a.writeEvent(c, "end", "done")
			break
		}

		content := parseStreamChunk(raw)
		if content != "" {
			fullText.WriteString(content)
			jsonEncoded, _ := json.Marshal(map[string]string{"text": content})
			fmt.Fprintf(c.Writer, "data: %s\n\n", jsonEncoded)
			c.Writer.Flush()
		}
	}

	return fullText.String()
}

// SummarizerAgent handles summarization requests.
type SummarizerAgent struct{}

func (a *SummarizerAgent) Handle(question string, ctx *AgentContext) (string, error) {
	if ctx.Post == nil {
		return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö", nil
	}
	contextText := ctx.Post.Content
	systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô BSO Space Blog
‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£
-----
` + contextText + `
-----`

	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": false,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}
	config := map[string]string{
		"api_key":       os.Getenv("AI_API_KEY"),
		"model":         os.Getenv("AI_MODEL"),
		"host":          os.Getenv("AI_HOST"),
		"use_self_host": os.Getenv("AI_SELF_HOST"),
	}
	resp, err := SendLLMRequestToOpenRouter(payload, config)
	if err != nil {
		return "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI", err
	}
	return strings.TrimSpace(resp), nil
}

// SearchAgent handles blog search requests.
type SearchAgent struct{}

func (a *SearchAgent) Handle(question string, ctx *AgentContext) (string, error) {
	systemPrompt := `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô BSO Space Blog
‡πÇ‡∏õ‡∏£‡∏î‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠ external source (mock)
‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
`
	// ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ vector search/external API ‡πÑ‡∏î‡πâ
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": false,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}
	config := map[string]string{
		"api_key":       os.Getenv("AI_API_KEY"),
		"model":         os.Getenv("AI_MODEL"),
		"host":          os.Getenv("AI_HOST"),
		"use_self_host": os.Getenv("AI_SELF_HOST"),
	}
	resp, err := SendLLMRequestToOpenRouter(payload, config)
	if err != nil {
		return "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI", err
	}
	return strings.TrimSpace(resp), nil
}

// FallbackAgent handles unknown or unsupported intents.
type FallbackAgent struct{}

func (a *FallbackAgent) Handle(question string, ctx *AgentContext) (string, error) {
	return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏∞ üòä", nil
}
