package ai

import (
	"bufio"
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"rag-searchbot-backend/internal/models"
	"rag-searchbot-backend/internal/post"
	"strings"

	"github.com/gin-gonic/gin"
)

// Intent represents the type of user question.

// Agent is the interface for all agents.
type Agent interface {
	Handle(question string, ctx *AgentContext) (string, error)
}

// AgentContext provides context for agent processing.
type AgentContext struct {
	Post    *models.Post
	User    *models.User
	PosRepo post.PostRepositoryInterface
	// à¹€à¸žà¸´à¹ˆà¸¡ field à¸­à¸·à¹ˆà¸™à¹† à¹„à¸”à¹‰ à¹€à¸Šà¹ˆà¸™ Embeddings, Logger, etc.
}

// ErrInsufficientContext is returned by BlogAgent when RAG context is not enough.
var ErrInsufficientContext = fmt.Errorf("insufficient context for RAG")

// IntentClassifier uses LLM (OpenRouter) to classify the question intent.
func IntentClassifier(question string) Intent {
	// Prepare system prompt for LLM
	systemPrompt := `
You are an intent classifier for a blog Q&A system. 
Classify the user's question into one of these intents:
- blog_question: à¸–à¸²à¸¡à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸šà¸—à¸„à¸§à¸²à¸¡ à¹€à¸Šà¹ˆà¸™ "à¸šà¸—à¸„à¸§à¸²à¸¡à¸™à¸µà¹‰à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸­à¸°à¹„à¸£", "RAG à¸„à¸·à¸­à¸­à¸°à¹„à¸£"
- summarize_post: à¸‚à¸­à¹ƒà¸«à¹‰à¸ªà¸£à¸¸à¸›à¸šà¸—à¸„à¸§à¸²à¸¡ à¹€à¸Šà¹ˆà¸™ "à¸Šà¹ˆà¸§à¸¢à¸ªà¸£à¸¸à¸›à¹ƒà¸«à¹‰à¸«à¸™à¹ˆà¸­à¸¢"
- greeting_farewell: à¸—à¸±à¸à¸—à¸²à¸¢à¸«à¸£à¸·à¸­à¸à¸¥à¹ˆà¸²à¸§à¸¥à¸² à¹€à¸Šà¹ˆà¸™ "à¸ªà¸§à¸±à¸ªà¸”à¸µ", "à¸¥à¸²à¸à¹ˆà¸­à¸™"
- unknown: à¹„à¸¡à¹ˆà¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸„à¸³à¸–à¸²à¸¡`

	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": false,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}
	config := map[string]string{
		"api_key":       os.Getenv("AI_API_KEY"),
		"model":         os.Getenv("AI_MODEL"),
		"host":          os.Getenv("AI_HOST"),
		"use_self_host": os.Getenv("AI_SELF_HOST"),
	}
	log.Printf("IntentClassifier payload: %+v", payload)
	resp, err := SendLLMRequestToOpenRouter(payload, config)
	if err != nil {
		log.Printf("IntentClassifier error: %v", err)
		return IntentUnknown
	}

	// log.Printf("IntentClassifier LLM raw response: %q", resp)
	return parseIntentFromLLM(resp)
}

// Helper methods
func writeEvent(c *gin.Context, event, data string) {
	fmt.Fprintf(c.Writer, "event: %s\ndata: %s\n\n", event, data)
	c.Writer.Flush()
}

func writeErrorEvent(c *gin.Context, message string) {
	fmt.Fprintf(c.Writer, "event: error\ndata: %s\n\n", message)
	c.Writer.Flush()
}

func parseStreamChunk(raw []byte) string {
	var chunk map[string]interface{}
	if err := json.Unmarshal(raw, &chunk); err != nil {
		return ""
	}

	// Handle Ollama format
	if message, ok := chunk["message"].(map[string]interface{}); ok {
		if content, ok := message["content"].(string); ok {
			return content
		}
	}

	// Handle OpenAI/OpenRouter format
	if choices, ok := chunk["choices"].([]interface{}); ok && len(choices) > 0 {
		choice := choices[0].(map[string]interface{})
		if delta, ok := choice["delta"].(map[string]interface{}); ok {
			if content, ok := delta["content"].(string); ok {
				return content
			}
		}
	}

	return ""
}

// AGENT : Summarize post agent
func StreamPostSummaryAgent(c *gin.Context, question string, htmlContent string) string {
	// 1. à¸ªà¸£à¹‰à¸²à¸‡ system prompt
	systemPrompt := fmt.Sprintf(`à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸ªà¸£à¸¸à¸›à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸šà¸—à¸„à¸§à¸²à¸¡à¹ƒà¸™ BSO Space Blog
à¹‚à¸›à¸£à¸”à¸ªà¸£à¸¸à¸›à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸à¸£à¸°à¸Šà¸±à¸š à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢ à¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£
-----
%s
-----`, htmlContent)

	// 2. à¸„à¸³à¸™à¸§à¸“ token
	// inputText := systemPrompt + "\n" + question
	// inputTokens := token.CountTokens(inputText)

	// 3. à¹€à¸•à¸£à¸µà¸¢à¸¡ payload
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": true,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}

	// 4. à¹€à¸•à¸£à¸µà¸¢à¸¡ HTTP request
	body, _ := json.Marshal(payload)
	req, _ := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+os.Getenv("AI_API_KEY"))
	req.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	req.Header.Set("X-Title", "https://blog.bsospace.com")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil || resp.StatusCode != http.StatusOK {
		writeErrorEvent(c, "à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ LLM à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
		return ""
	}
	defer resp.Body.Close()

	// 5. à¸•à¸±à¹‰à¸‡ header à¸ªà¸³à¸«à¸£à¸±à¸š SSE
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Writer.Flush()

	// 6. à¸ªà¹ˆà¸‡ event à¹€à¸£à¸´à¹ˆà¸¡
	writeEvent(c, "start", "à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸ªà¸£à¸¸à¸›à¹€à¸™à¸·à¹‰à¸­à¸«à¸²")

	// 7. à¸­à¹ˆà¸²à¸™à¹à¸¥à¸°à¸ªà¹ˆà¸‡ stream
	fullText := streamLLMResponse(c, resp)

	// 8. à¸ªà¹ˆà¸‡ event à¸ˆà¸š
	writeEvent(c, "end", "à¸ªà¸£à¸¸à¸›à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™")

	// 9. return full text
	return fullText
}

// AGENT: greeting_farewell agent
func StreamGreetingFarewellAgent(c *gin.Context, question string) string {
	// 1. à¸ªà¸£à¹‰à¸²à¸‡ system prompt
	systemPrompt := `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸—à¸±à¸à¸—à¸²à¸¢à¹à¸¥à¸°à¸à¸¥à¹ˆà¸²à¸§à¸¥à¸²à¹ƒà¸™ BSO Space
à¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¸à¸—à¸²à¸¢à¸«à¸£à¸·à¸­à¸à¸¥à¹ˆà¸²à¸§à¸¥à¸²à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£à¹à¸¥à¸°à¸ªà¸¸à¸ à¸²à¸ž 
à¸„à¸³à¸–à¸²à¸¡: ` + question

	// 2. à¹€à¸•à¸£à¸µà¸¢à¸¡ payload
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": true,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}

	// 3. à¹€à¸•à¸£à¸µà¸¢à¸¡ HTTP request
	body, _ := json.Marshal(payload)
	req, _ := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+os.Getenv("AI_API_KEY"))
	req.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	req.Header.Set("X-Title", "https://blog.bsospace.com")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil || resp.StatusCode != http.StatusOK {
		writeErrorEvent(c, "à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ LLM à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
		return ""
	}
	defer resp.Body.Close()

	// 4. à¸•à¸±à¹‰à¸‡ header à¸ªà¸³à¸«à¸£à¸±à¸š SSE
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Writer.Flush()

	// 5. à¸ªà¹ˆà¸‡ event à¹€à¸£à¸´à¹ˆà¸¡
	writeEvent(c, "start", "à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¸à¸—à¸²à¸¢/à¸à¸¥à¹ˆà¸²à¸§à¸¥à¸²")

	// 6. à¸­à¹ˆà¸²à¸™à¹à¸¥à¸°à¸ªà¹ˆà¸‡ stream
	fullText := streamLLMResponse(c, resp)

	// 7. à¸ªà¹ˆà¸‡ event à¸ˆà¸š
	writeEvent(c, "end", "à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¸à¸—à¸²à¸¢/à¸à¸¥à¹ˆà¸²à¸§à¸¥à¸²à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™")
	return fullText
}

// AGENT: Generic question agent
func StreamGenericQuestionAgent(c *gin.Context, question string) {
	// 1. à¸ªà¸£à¹‰à¸²à¸‡ system prompt
	systemPrompt := `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¹ƒà¸™ BSO Space
à¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸¸à¸ à¸²à¸žà¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ
à¸„à¸³à¸–à¸²à¸¡: ` + question

	// 2. à¹€à¸•à¸£à¸µà¸¢à¸¡ payload
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": true,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}

	// 3. à¹€à¸•à¸£à¸µà¸¢à¸¡ HTTP request
	body, _ := json.Marshal(payload)
	req, _ := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+os.Getenv("AI_API_KEY"))
	req.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	req.Header.Set("X-Title", "https://blog.bsospace.com")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil || resp.StatusCode != http.StatusOK {
		writeErrorEvent(c, "à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ LLM à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
		return
	}
	defer resp.Body.Close()

	// 4. à¸•à¸±à¹‰à¸‡ header à¸ªà¸³à¸«à¸£à¸±à¸š SSE
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Writer.Flush()

	// 5. à¸ªà¹ˆà¸‡ event à¹€à¸£à¸´à¹ˆà¸¡
	writeEvent(c, "start", "à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›")

	// 6. à¸­à¹ˆà¸²à¸™à¹à¸¥à¸°à¸ªà¹ˆà¸‡ stream
	streamLLMResponse(c, resp)

	// 7. à¸ªà¹ˆà¸‡ event à¸ˆà¸š
	writeEvent(c, "end", "à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸›à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™")
}

// parseIntentFromLLM extracts the intent keyword from LLM response.
func parseIntentFromLLM(resp string) Intent {
	resp = strings.TrimSpace(resp)

	// Try to parse as JSON (OpenRouter format)
	var parsed struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
		} `json:"choices"`
	}
	if err := json.Unmarshal([]byte(resp), &parsed); err == nil && len(parsed.Choices) > 0 {
		intent := strings.TrimSpace(parsed.Choices[0].Message.Content)
		switch intent {
		case "blog_question":
			return IntentBlogQuestion
		case "summarize_post":
			return IntentSummarizePost
		case "search_blog":
			return IntentSearchBlog
		case "generic_question":
			return IntentGeneric
		case "greeting_farewell":
			return IntentGreetingFarewell
		default:
			return IntentUnknown
		}
	}

	// fallback: direct string match
	// fallback: direct string match
	resp = strings.ToLower(resp)
	resp = strings.Trim(resp, "\"") // <-- à¹€à¸žà¸´à¹ˆà¸¡à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰à¹€à¸žà¸·à¹ˆà¸­à¸à¸±à¸™ "blog_question"
	switch resp {
	case "blog_question":
		return IntentBlogQuestion
	case "summarize_post":
		return IntentSummarizePost
	case "search_blog":
		return IntentSearchBlog
	case "generic_question":
		return IntentGeneric
	case "greeting_farewell":
		return IntentGreetingFarewell
	default:
		return IntentUnknown
	}

}

// SendLLMRequestToOpenRouter is a utility for agents to call OpenRouter or Ollama.
// Returns the response body as a string (for non-streaming use).
func SendLLMRequestToOpenRouter(payload map[string]interface{}, config map[string]string) (string, error) {
	body, _ := json.Marshal(payload)

	useSelfHost := config["use_self_host"] == "true"
	if useSelfHost {
		host := config["host"]
		resp, err := http.Post(host+"/api/chat", "application/json", bytes.NewBuffer(body))
		if err != nil {
			return "", err
		}
		defer resp.Body.Close()
		respBody, _ := io.ReadAll(resp.Body)
		if resp.StatusCode != http.StatusOK {
			return "", fmt.Errorf("Ollama error: %s", string(respBody))
		}
		return string(respBody), nil
	}

	apiKey := config["api_key"]
	if apiKey == "" {
		return "", fmt.Errorf("OpenRouter API key missing")
	}
	request, err := http.NewRequest("POST", "https://openrouter.ai/api/v1/chat/completions", bytes.NewBuffer(body))
	if err != nil {
		return "", err
	}
	request.Header.Set("Content-Type", "application/json")
	request.Header.Set("Authorization", "Bearer "+apiKey)
	request.Header.Set("HTTP-Referer", "https://blog.bsospace.com")
	request.Header.Set("X-Title", "https://blog.bsospace.com")
	client := &http.Client{}
	log.Printf("Sending intent classification to OpenRouter: %+v", payload)
	resp, err := client.Do(request)
	log.Printf("OpenRouter response status: %v", resp.StatusCode)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()
	respBody, _ := io.ReadAll(resp.Body)
	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("OpenRouter error: %s", string(respBody))
	}
	return string(respBody), nil
}

// BlogAgent handles blog content questions and generic questions.
type BlogAgent struct{}

// streamLLMResponse streams LLM response and calls onChunk for each content chunk.
func streamLLMResponse(c *gin.Context, resp *http.Response) string {
	reader := bufio.NewReader(resp.Body)
	var fullText strings.Builder

	for {
		line, err := reader.ReadBytes('\n')
		if err != nil {
			if err == io.EOF {
				// a.logger.Info("LLM stream finished")
				writeEvent(c, "end", "done")
			} else {
				// a.logger.Error("Error reading LLM stream", zap.Error(err))
				writeErrorEvent(c, "Stream reading error")
			}
			break
		}

		if !bytes.HasPrefix(line, []byte("data: ")) {
			continue
		}

		raw := bytes.TrimSpace(line[6:])
		if len(raw) == 0 {
			continue
		}

		if bytes.Equal(raw, []byte("[DONE]")) {
			// a.writeEvent(c, "end", "done")
			break
		}

		content := parseStreamChunk(raw)
		if content != "" {
			fullText.WriteString(content)
			jsonEncoded, _ := json.Marshal(map[string]string{"text": content})
			fmt.Fprintf(c.Writer, "data: %s\n\n", jsonEncoded)
			c.Writer.Flush()
		}
	}

	return fullText.String()
}

// SummarizerAgent handles summarization requests.
type SummarizerAgent struct{}

func (a *SummarizerAgent) Handle(question string, ctx *AgentContext) (string, error) {
	if ctx.Post == nil {
		return "à¹„à¸¡à¹ˆà¸žà¸šà¹‚à¸žà¸ªà¸•à¹Œà¸™à¸µà¹‰à¹ƒà¸™à¸£à¸°à¸šà¸š", nil
	}
	contextText := ctx.Post.Content
	systemPrompt := `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸ªà¸£à¸¸à¸›à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸šà¸—à¸„à¸§à¸²à¸¡à¹ƒà¸™ BSO Space Blog
à¹‚à¸›à¸£à¸”à¸ªà¸£à¸¸à¸›à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸à¸£à¸°à¸Šà¸±à¸š à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢ à¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£
-----
` + contextText + `
-----`

	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": false,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}
	config := map[string]string{
		"api_key":       os.Getenv("AI_API_KEY"),
		"model":         os.Getenv("AI_MODEL"),
		"host":          os.Getenv("AI_HOST"),
		"use_self_host": os.Getenv("AI_SELF_HOST"),
	}
	resp, err := SendLLMRequestToOpenRouter(payload, config)
	if err != nil {
		return "à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ AI", err
	}
	return strings.TrimSpace(resp), nil
}

// SearchAgent handles blog search requests.
type SearchAgent struct{}

func (a *SearchAgent) Handle(question string, ctx *AgentContext) (string, error) {
	systemPrompt := `à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸„à¹‰à¸™à¸«à¸²à¸šà¸—à¸„à¸§à¸²à¸¡à¹ƒà¸™ BSO Space Blog
à¹‚à¸›à¸£à¸”à¸„à¹‰à¸™à¸«à¸²à¸šà¸—à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸£à¸·à¸­ external source (mock)
à¸–à¹‰à¸²à¸žà¸šà¹ƒà¸«à¹‰à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸à¸²à¸£à¸Šà¸·à¹ˆà¸­à¸šà¸—à¸„à¸§à¸²à¸¡ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸žà¸šà¹ƒà¸«à¹‰à¸•à¸­à¸šà¸§à¹ˆà¸² "à¹„à¸¡à¹ˆà¸žà¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡"
`
	// à¹ƒà¸™à¸­à¸™à¸²à¸„à¸•à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ vector search/external API à¹„à¸”à¹‰
	payload := map[string]interface{}{
		"model":  os.Getenv("AI_MODEL"),
		"stream": false,
		"messages": []map[string]string{
			{"role": "system", "content": systemPrompt},
			{"role": "user", "content": question},
		},
	}
	config := map[string]string{
		"api_key":       os.Getenv("AI_API_KEY"),
		"model":         os.Getenv("AI_MODEL"),
		"host":          os.Getenv("AI_HOST"),
		"use_self_host": os.Getenv("AI_SELF_HOST"),
	}
	resp, err := SendLLMRequestToOpenRouter(payload, config)
	if err != nil {
		return "à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ AI", err
	}
	return strings.TrimSpace(resp), nil
}

// FallbackAgent handles unknown or unsupported intents.
type FallbackAgent struct{}

func (a *FallbackAgent) Handle(question string, ctx *AgentContext) (string, error) {
	return "à¸‚à¸­à¸­à¸ à¸±à¸¢ à¹„à¸¡à¹ˆà¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸„à¸³à¸–à¸²à¸¡ à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡à¸«à¸£à¸·à¸­à¸–à¸²à¸¡à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸­à¸·à¹ˆà¸™à¹„à¸”à¹‰à¸„à¹ˆà¸° ðŸ˜Š", nil
}
